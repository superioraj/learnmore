#  Handtracking sample 4,8 샘플
```
import cv2
import mediapipe as mp

# Mediapipe 손 검출 라이브러리 초기화
mp_hands = mp.solutions.hands
hands = mp_hands.Hands()
mp_drawing = mp.solutions.drawing_utils

# 웹캠으로부터 영상을 받아오기 위한 코드
cap = cv2.VideoCapture(0)

while cap.isOpened():
    ret, frame = cap.read()

    if not ret:
        continue

    # Mediapipe는 RGB 이미지를 사용하기 때문에, BGR에서 RGB로 변환
    frame = cv2.flip(frame, 1)
    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # 손을 검출
    results = hands.process(image)

    # 검출된 손의 랜드마크를 화면에 그림
    if results.multi_hand_landmarks:
        for landmarks in results.multi_hand_landmarks:
            mp_drawing.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)

            # 손가락 끝 좌표 값을 화면에 출력
            
            x = landmarks.landmark[4].x
            y = landmarks.landmark[4].y
            z = landmarks.landmark[4].z
            text_04 = f"text_04>> x: {x:.4f}, y: {y:.4f}, z: {z:.4f}"
            cv2.putText(frame, text_04, (25, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)
            
            x = landmarks.landmark[8].x
            y = landmarks.landmark[8].y
            z = landmarks.landmark[8].z
            text_08 = f"text_08>> x: {x:.4f}, y: {y:.4f}, z: {z:.4f}"
            cv2.putText(frame, text_08, (25, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)

    # 영상을 화면에 출력
    cv2.imshow('Hand Tracking', frame)

    if cv2.waitKey(10) & 0xFF == ord('q'):
        break

hands.close()
cap.release()
cv2.destroyAllWindows()
```
